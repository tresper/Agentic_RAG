{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agentic RAG with Llamaindex\n",
    "source: https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/1/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, SummaryIndex, VectorStoreIndex\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters, FilterCondition\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "from utils import display_text\n",
    "from utils import filenames_in_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:30px;\">Setup</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary for running in Jupyter Notebook \n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">LlamaIndex RAG functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_path: str):\n",
    "    \"\"\"Load documents from the specified file path.\"\"\"\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    return documents\n",
    "\n",
    "def create_nodes(documents):\n",
    "    \"\"\"Create nodes from loaded documents.\"\"\"\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    return nodes\n",
    "\n",
    "def create_vector_index(nodes):\n",
    "    \"\"\"Create a vector index from nodes.\"\"\"\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "    return vector_index\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    vector_index: VectorStoreIndex, \n",
    "    page_numbers: Optional[List[str]] = None\n",
    ") -> str:\n",
    "    \"\"\"Use to answer questions over a given paper.\n",
    "\n",
    "    Useful if you have specific questions over the paper.\n",
    "    Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "    Args:\n",
    "        query (str): the string query to be embedded.\n",
    "        page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE \n",
    "            if we want to perform a vector search\n",
    "            over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    page_numbers = page_numbers or []\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(metadata_dicts, condition=FilterCondition.OR)\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def create_vector_query_tool(name: str, vector_index: VectorStoreIndex):\n",
    "    \"\"\"Create a vector query tool.\"\"\"\n",
    "    return FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\",\n",
    "        fn=lambda query, page_numbers=None: vector_query(query, vector_index, page_numbers)\n",
    "    )\n",
    "\n",
    "def create_summary_index(nodes):\n",
    "    \"\"\"Create a summary index from nodes.\"\"\"\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    return summary_index\n",
    "\n",
    "def create_summary_tool(name: str, summary_index: SummaryIndex):\n",
    "    \"\"\"Create a summary tool.\"\"\"\n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode=\"tree_summarize\",\n",
    "        use_async=True,\n",
    "    )\n",
    "    return QueryEngineTool.from_defaults(\n",
    "        name=f\"summary_tool_{name}\",\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            \"Use ONLY IF you want to get a holistic summary related to {name} \"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">Load Data into RAG</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Foundation_Models_Enterprise_Workflows.pdf',\n",
       " 'Ajua_Q2_2023_benchmark_report.txt',\n",
       " 'metagpt.pdf']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./input_docs_example\"\n",
    "papers = filenames_in_directory(file_path)\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: Foundation_Models_Enterprise_Workflows.pdf\n",
      "Getting tools for paper: Ajua_Q2_2023_benchmark_report.txt\n",
      "Getting tools for paper: metagpt.pdf\n"
     ]
    }
   ],
   "source": [
    "def process_papers(papers, file_path):\n",
    "    \"\"\"\n",
    "    Process a list of papers and create tools for each paper.\n",
    "\n",
    "    Args:\n",
    "        papers (list): A list of paper filenames.\n",
    "        file_path (str): The path to the directory containing the papers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each paper to its associated tools.\n",
    "    \"\"\"\n",
    "    paper_to_tools_dict = {}\n",
    "    \n",
    "    for paper in papers:\n",
    "        name = f\"{Path(paper).stem}\"\n",
    "        print(f\"Getting tools for paper: {paper}\")\n",
    "        \n",
    "        # Assuming the following functions are defined elsewhere\n",
    "        documents = load_documents(f\"{file_path}/{Path(paper)}\")\n",
    "        nodes = create_nodes(documents)\n",
    "        vector_index = create_vector_index(nodes)\n",
    "        vector_query_tool = create_vector_query_tool(name, vector_index)\n",
    "        summary_index = create_summary_index(nodes)\n",
    "        summary_tool = create_summary_tool(name, summary_index)\n",
    "        \n",
    "        paper_to_tools_dict[paper] = [vector_query_tool, summary_tool]\n",
    "    \n",
    "    return paper_to_tools_dict\n",
    "\n",
    "paper_to_tools_dict = process_papers(papers, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tools: 6\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of tools from all papers into a single list `all_tools`\n",
    "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]\n",
    "print(f\"number of tools: {len(all_tools)}\") #check (should be 2 * number of papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an \"object\" index and retriever over these tools\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n",
    "\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FunctionCallingAgentWorker\n",
    "# Verbose shows output of the agent's actions.\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given papers.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">Try it</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, QA Engineer, CEO, individuals conducting experiments, designing modules, providing feedback, outlining methods, contributing to the write-up, team members assisting with experiments, comparisons, and creating illustrative figures, User Interface Designer, Data Scientist for data analysis, and System Agent. Each role has specific responsibilities and expertise tailored to different aspects of the collaborative framework within the MetaGPT development process.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"communication between agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "Communication between agent roles in MetaGPT is structured and efficient, facilitated through mechanisms such as role specialization, workflow management, and sharing mechanisms like message pools and subscriptions. This structured communication approach enhances role communication efficiency, allowing agents to obtain directional information from other roles and public information from the environment. Agents publish structured messages in a shared message pool and can subscribe to relevant messages based on their profiles, ensuring transparent access to information and efficient task execution within the multi-agent collaboration framework.\n",
      "=== LLM Response ===\n",
      "In MetaGPT, the agent roles include the Product Manager, Architect, Project Manager, Engineer, QA Engineer, CEO, individuals conducting experiments, designing modules, providing feedback, outlining methods, contributing to the write-up, team members assisting with experiments, comparisons, creating illustrative figures, User Interface Designer, Data Scientist for data analysis, and System Agent. Each role has specific responsibilities tailored to different aspects of the collaborative framework.\n",
      "\n",
      "Communication between these agent roles in MetaGPT is structured and efficient. It is facilitated through mechanisms such as role specialization, workflow management, and sharing mechanisms like message pools and subscriptions. This structured approach enhances communication efficiency, allowing agents to obtain directional information from other roles and public information from the environment. Agents publish structured messages in a shared message pool and can subscribe to relevant messages based on their profiles, ensuring transparent access to information and efficient task execution within the multi-agent collaboration framework.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In MetaGPT, the agent roles include the Product Manager, Architect, Project\n",
      "Manager, Engineer, QA Engineer, CEO, individuals conducting experiments,\n",
      "designing modules, providing feedback, outlining methods, contributing to the\n",
      "write-up, team members assisting with experiments, comparisons, creating\n",
      "illustrative figures, User Interface Designer, Data Scientist for data\n",
      "analysis, and System Agent. Each role has specific responsibilities tailored to\n",
      "different aspects of the collaborative framework.  Communication between these\n",
      "agent roles in MetaGPT is structured and efficient. It is facilitated through\n",
      "mechanisms such as role specialization, workflow management, and sharing\n",
      "mechanisms like message pools and subscriptions. This structured approach\n",
      "enhances communication efficiency, allowing agents to obtain directional\n",
      "information from other roles and public information from the environment.\n",
      "Agents publish structured messages in a shared message pool and can subscribe\n",
      "to relevant messages based on their profiles, ensuring transparent access to\n",
      "information and efficient task execution within the multi-agent collaboration\n",
      "framework.\n"
     ]
    }
   ],
   "source": [
    "print(display_text(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: input_docs_example/metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-06-24\n",
      "last_modified_date: 2024-05-30\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 2\n",
      "file_name: metagpt.pdf\n",
      "file_path: input_docs_example/metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-06-24\n",
      "last_modified_date: 2024-05-30\n",
      "\n",
      "Preprint\n",
      "Figure 1: The software development SOPs between MetaGPT and real-world human teams.\n",
      "In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases\n",
      "its ability to decompose complex tasks into specific actionable procedures assigned to various roles\n",
      "(e.g., Product Manager, Architect, Engineer, etc.).\n",
      "documents, design artifacts, flowcharts, and interface specifications. The use of intermediate struc-\n",
      "tured outputs significantly increases the success rate of target code generation. Because it helps\n",
      "maintain consistency in communication, minimizing ambiguities and errors during collaboration.\n",
      "More graphically, in a company simulated by MetaGPT, all employees follow a strict and stream-\n",
      "lined workflow, and all their handovers must comply with certain established standards. This reduces\n",
      "the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frame-\n",
      "works, like: “ Hi, hello and how are you?” – Alice (Product Manager); “ Great! Have you had\n",
      "lunch?” – Bob (Architect).\n",
      "Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context,\n",
      "we adopt meta-programming1as ”programming to program”, in contrast to the broader fields of meta\n",
      "learning and ”learning to learn” (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber,\n",
      "2006; Finn et al., 2017).\n",
      "This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al.,\n",
      "2020) and recent projects such as CodeLlama (Rozi `ere et al., 2023) and WizardCoder (Luo\n",
      "et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient meta-\n",
      "programming through a well-organized group of specialized agents. Each agent has a specific role\n",
      "and expertise, following some established standards. This allows for automatic requirement analysis,\n",
      "system design, code generation, modification, execution, and debugging during runtime, highlight-\n",
      "ing how agent-based techniques can enhance meta-programming.\n",
      "To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and\n",
      "MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT\n",
      "achieves a new state-of-the-art (SoTA) with 85.9% and 87.7% in Pass@1. When compared to other\n",
      "popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al.,\n",
      "2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).\n",
      "MetaGPT also stands out in handling higher levels of software complexity and offering extensive\n",
      "functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a 100% task com-\n",
      "pletion rate, demonstrating the robustness and efficiency (time and token costs) of our design.\n",
      "We summarize our contributions as follows:\n",
      "1https://en.wikipedia.org/w/index.php?title=Metaprogramming\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[1].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: According to Ajua, tell me about NPS and then how it is useful.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Ajua_Q2_2023_benchmark_report with args: {\"input\": \"NPS\"}\n",
      "=== Function Output ===\n",
      "NPS, or Net Promoter Score, is a metric utilized by businesses to assess customer loyalty and satisfaction by determining the likelihood of customers to recommend a company's products or services to others. This metric categorizes customers into Promoters, Passives, or Detractors based on their responses to a specific question, with Promoters being loyal advocates, Passives being satisfied but not enthusiastic, and Detractors being unhappy customers. The final NPS score is calculated by subtracting the percentage of Detractors from the percentage of Promoters, providing a valuable insight into customer perception and loyalty.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Ajua_Q2_2023_benchmark_report with args: {\"input\": \"usefulness of NPS\"}\n",
      "=== Function Output ===\n",
      "NPS is a valuable metric for businesses to measure customer loyalty, understand customer perception, and categorize customers based on their likelihood to recommend a product or service. It helps in identifying areas for improvement, gauging customer satisfaction levels, predicting revenue and market share trends, and making informed decisions to enhance customer experience and drive growth. Tracking NPS over time allows companies to assess their performance, measure the effectiveness of their customer service efforts, and gain insights into customer sentiment and loyalty.\n",
      "=== LLM Response ===\n",
      "Net Promoter Score (NPS) is a metric used by businesses to evaluate customer loyalty and satisfaction by assessing the likelihood of customers to recommend a company's products or services to others. It categorizes customers into Promoters, Passives, or Detractors based on their responses to a specific question. NPS is useful for businesses as it provides insights into customer perception, loyalty, areas for improvement, customer satisfaction levels, revenue trends, and market share predictions. Tracking NPS over time helps companies assess performance, measure the effectiveness of customer service efforts, and understand customer sentiment and loyalty.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"According to Ajua, tell me about NPS and then how it is useful.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Promoter Score (NPS) is a metric used by businesses to evaluate customer\n",
      "loyalty and satisfaction by assessing the likelihood of customers to recommend\n",
      "a company's products or services to others. It categorizes customers into\n",
      "Promoters, Passives, or Detractors based on their responses to a specific\n",
      "question. NPS is useful for businesses as it provides insights into customer\n",
      "perception, loyalty, areas for improvement, customer satisfaction levels,\n",
      "revenue trends, and market share predictions. Tracking NPS over time helps\n",
      "companies assess performance, measure the effectiveness of customer service\n",
      "efforts, and understand customer sentiment and loyalty.\n"
     ]
    }
   ],
   "source": [
    "print(display_text(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: input_docs_example/Ajua_Q2_2023_benchmark_report.txt\n",
      "file_name: Ajua_Q2_2023_benchmark_report.txt\n",
      "file_type: text/plain\n",
      "file_size: 34850\n",
      "creation_date: 2024-06-24\n",
      "last_modified_date: 2024-06-24\n",
      "\n",
      "﻿AJUA\n",
      "\n",
      "\n",
      "NPS Industry Benchmarks Q2 2023 \n",
      "April 2023 – June 2023\n",
      "________________\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "- Background - 3\n",
      "- Objectives - 4\n",
      "- Methodology - 5\n",
      "- Telcos - 7\n",
      "- Mobile Money Lenders - 10\n",
      "- Food & Beverage - 15\n",
      "- Online Food Delivery Platforms - 19\n",
      "- Retail/Modern Trade - 21\n",
      "- Online Delivery Platforms - 25\n",
      "- Pharmacies - 27\n",
      "- Energy - 31\n",
      "- Banking - 37\n",
      "- Insurance - 41\n",
      "- Healthcare - 44\n",
      "________________\n",
      "\n",
      "\n",
      "A remarkable customer experience is critical to the sustained growth of any business. A positive customer experience promotes loyalty, helps businesses retain customers, and encourages brand advocacy.\n",
      "Today, customers have the power, not the sellers. Who gave them this power? Us — with help from the world wide web. The present customer has a plethora of options to choose from at their fingertips, and the resources necessary to educate themselves and make purchases on their own.\n",
      "This is why it’s so important to provide a remarkable customer experience and make them want to continue doing business with you — customers are the best resource for growing your brand awareness. It is therefore imperative that businesses measure their customer experience to determine what they are doing well and where there’s room for improvement!\n",
      "The NPS( Net Promoter Score) is one metric that businesses need to use to measure and track customer loyalty to help them scale. Besides measuring customer loyalty, Bain and Company research shows that NPS scores predicted between 20% and 60% of revenue or market share trends, depending on the company.\n",
      "NPS scores determine segmenting between poor and positive feedback. It measures customer perception based on one simple question: How likely are you to recommend [Organization X/Product Y/Service Z] to a friend or colleague?\n",
      "Respondents give a rating between 0 (not at all likely) and 10 (extremely likely) and, depending on their response, customers fall into one of these three categories to establish an NPS score:\n",
      "◊ Promoters respond with a score of 9 or 10 and are typically loyal and enthusiastic customers.\n",
      "◊ Passives respond with a score of 7 or 8. They are satisfied with your service but not happy enough to be considered promoters.\n",
      "◊ Detractors respond with a score of 0 to 6. These are unhappy customers who are unlikely to buy from you again, and may even discourage others from buying from you.\n",
      "It’s simple to calculate your final NPS score – just subtract the percentage of Detractors from the percentage of Promoters.\n",
      "For example, if 10% of respondents are Detractors, 20% are Passives and 70% are Promoters, your NPS score would be 70-10 = 60.\n",
      "◊ Detractors (score 0-6) are unhappy customers who can damage your brand and impede growth through negative word-of-mouth.\n",
      "◊ Passives (score 7-8) are satisfied but unenthusiastic customers who are vulnerable to competitive offerings.\n",
      "◊ Promoters (score 9-10) are loyal enthusiasts who will keep buying and fuel growth by referring others.\n",
      "Positive customer experience is essential for achieving customer satisfaction, word-of-mouth communications, loyalty, and competitive advantage across the globe.\n",
      "________________\n",
      "\n",
      "\n",
      "Besides measuring customer loyalty, Bain and Company research shows that NPS scores predict between 20% and 60% of revenue or market share trends, depending on the company. Additionally, to\n",
      "be able to measure the effectiveness of interactions between the business and its customers at each touch point requires a measure that is simple to use and communicate to a variety of stakeholders, ranging from frontline staff to company directors and shareholders. NPS provides both rigor and simplicity.\n",
      "Additionally Net Promoter research by NICE Satmetrix, the co-developer of Net Promoter, shows that companies with scores higher than their competitors grow faster and are more successful.\n",
      "Ajua, in addition to providing a platform for integrated customer experience and loyalty, provides tools to measure and track NPS at each customer touch point. Ajua also aims at providing industry and top brand Net Promoter Scores to help businesses make comparisons and set improvement goals.\n",
      "\n",
      "\n",
      "IS GREAT CUSTOMER SERVICE REALLY WORTH THE EFFORT?\n",
      "\n",
      "\n",
      "The Rewards Of Great Service\n",
      "81% of companies with strong capabilities and competencies for delivering an excellent customer experience are outperforming their competition.\n",
      "\n",
      "\n",
      "The High Cost Of Bad Service\n",
      "Our research also shows that 91% of customers will not do business with you a second time if you botch the first encounter.\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: How did the NPS benchmark for Healthcare change from Q2'22 to Q2'23? \n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_Ajua_Q2_2023_benchmark_report with args: {\"query\": \"NPS benchmark Healthcare Q2'22 vs Q2'23\"}\n",
      "=== Function Output ===\n",
      "NPS benchmark for Healthcare in Q2'22 was 9, while in Q2'23 it increased to 20.\n",
      "=== LLM Response ===\n",
      "The NPS benchmark for Healthcare increased from 9 in Q2'22 to 20 in Q2'23.\n"
     ]
    }
   ],
   "source": [
    "#NOTE — Correct response: The NPS benchmark for Healthcare increased from 9 in Q2'22 to 20 in Q2'23.\n",
    "response = agent.query(\n",
    "    \"How did the NPS benchmark for Healthcare change from Q2'22 to Q2'23? \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: According to the Ajua report, how did the NPS benchmark for TELCO change from Q2'22 to Q2'23? \n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_Ajua_Q2_2023_benchmark_report with args: {\"query\": \"NPS benchmark TELCO Q2'22 vs Q2'23\"}\n",
      "=== Function Output ===\n",
      "Telco's NPS benchmark in Q2'22 was 29, while in Q2'23 it decreased to 24.\n",
      "=== LLM Response ===\n",
      "The NPS benchmark for TELCO decreased from 29 in Q2'22 to 24 in Q2'23 according to the Ajua report.\n"
     ]
    }
   ],
   "source": [
    "#NOTE — Correct response: The NPS benchmark for TELCO decreased from 29 in Q2'22 to 24 in Q2'23 according to the Ajua report.\n",
    "response = agent.chat(\n",
    "    \"According to the Ajua report, how did the NPS benchmark for TELCO change from Q2'22 to Q2'23? \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Which industry (not company) showed the best performance in the second quarter of 2023 according to the Ajua report? \n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_Ajua_Q2_2023_benchmark_report with args: {\"query\": \"best industry performance Q2'23\"}\n",
      "=== Function Output ===\n",
      "The Pharmacy Industry demonstrated the best performance in Q2'23 with an Overall Net Promoter Score (NPS) of 38.\n",
      "=== LLM Response ===\n",
      "According to the Ajua report, the Pharmacy Industry demonstrated the best performance in the second quarter of 2023 with an Overall Net Promoter Score (NPS) of 38.\n"
     ]
    }
   ],
   "source": [
    "#NOTE: Pharmacy is the correct answer. But needed to ask a carefully crafted question to get the answer.\n",
    "response = agent.chat(\n",
    "    \"Which industry (not company) showed the best performance in the second quarter of 2023 according to the Ajua report? \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What are the roots of automatic programming?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"Roots of automatic programming\"}\n",
      "=== Function Output ===\n",
      "The roots of automatic programming can be traced back to the early developments in the field, with initial ideas of recursive self-improvement informally proposed in 1965 and concretely implemented starting from 1987. Over time, concepts of mathematically optimal self-referential self-improvers were introduced, leading to advancements in learning algorithms and meta-learning. Recent work has leveraged Large Language Models (LLMs) to enhance performance on various tasks through recursive prompt modifications. Additionally, there have been explorations into self-referential mechanisms that adapt constraint prompts based on project experiences, aiming to improve individual agents within a system continuously.\n",
      "=== LLM Response ===\n",
      "The roots of automatic programming can be traced back to early developments in the field, with initial ideas of recursive self-improvement proposed informally in 1965 and concretely implemented starting from 1987. Concepts of mathematically optimal self-referential self-improvers have been introduced, leading to advancements in learning algorithms and meta-learning. Recent work has utilized Large Language Models (LLMs) to enhance performance on various tasks through recursive prompt modifications. There have also been explorations into self-referential mechanisms that adapt constraint prompts based on project experiences to continuously improve individual agents within a system.\n"
     ]
    }
   ],
   "source": [
    "# NOTE — The answer should come from the metaGPT paper.\n",
    "response = agent.chat(\n",
    "    \"What are the roots of automatic programming?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roots of automatic programming can be traced back to early developments in\n",
      "the field, with initial ideas of recursive self-improvement proposed informally\n",
      "in 1965 and concretely implemented starting from 1987. Concepts of\n",
      "mathematically optimal self-referential self-improvers have been introduced,\n",
      "leading to advancements in learning algorithms and meta-learning. Recent work\n",
      "has utilized Large Language Models (LLMs) to enhance performance on various\n",
      "tasks through recursive prompt modifications. There have also been explorations\n",
      "into self-referential mechanisms that adapt constraint prompts based on project\n",
      "experiences to continuously improve individual agents within a system.\n"
     ]
    }
   ],
   "source": [
    "print(display_text(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metagpt.pdf\n",
      "file_path: input_docs_example/metagpt.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16911937\n",
      "creation_date: 2024-06-24\n",
      "last_modified_date: 2024-05-30\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Summarize the paper discussing Multimodal Foundation Models and Enterprise Workflows.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Foundation_Models_Enterprise_Workflows with args: {\"input\": \"Multimodal Foundation Models and Enterprise Workflows\"}\n",
      "=== Function Output ===\n",
      "Multimodal foundation models play a crucial role in enhancing enterprise workflows by assisting in tasks such as documentation, knowledge transfer, and workflow improvement. These models have shown capabilities in generating accurate documentation, refining standard operating procedures (SOPs), and improving workflow quality without human intervention. However, challenges persist in achieving enterprise-level accuracy, particularly in areas like low-level error correction and accurately ranking SOPs based on quality as perceived by human annotators. The introduction of benchmarks like WONDERBREAD aims to encourage the development of more \"human-centered\" AI tools for enterprise applications and explore a broader range of business process management tasks.\n",
      "=== LLM Response ===\n",
      "The paper on Multimodal Foundation Models and Enterprise Workflows highlights the significant role of multimodal foundation models in enhancing enterprise workflows by aiding in tasks such as documentation, knowledge transfer, and workflow enhancement. These models have demonstrated capabilities in generating precise documentation, refining standard operating procedures (SOPs), and enhancing workflow quality autonomously. Challenges remain in achieving enterprise-level accuracy, especially in tasks like low-level error correction and accurately ranking SOPs based on quality as perceived by human annotators. Initiatives like the WONDERBREAD benchmark aim to promote the development of more \"human-centered\" AI tools for enterprise use and explore a wider range of business process management tasks.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Summarize the paper discussing Multimodal Foundation Models and Enterprise Workflows.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Compare and contrast (1) the paper discussing Multimodal Foundation Models and Enterprise Workflows and (2) the metagpt paper.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_Foundation_Models_Enterprise_Workflows with args: {\"input\": \"Multimodal Foundation Models and Enterprise Workflows\"}\n",
      "=== Function Output ===\n",
      "Multimodal Foundation Models are being utilized in enterprise workflows to enhance automation, decision-making processes, and overall efficiency within organizations. These models are trained on vast datasets and combine natural language understanding with visual processing capabilities to tackle various business process management (BPM) tasks. The models are evaluated based on their performance in generating Standard Operating Procedures (SOPs), segmenting demonstrations, answering questions, validating workflows, and improving SOP quality. While they have shown potential in improving the quality of their own SOPs and adapting to changing workflows, challenges remain in aligning model judgments with human judgments, particularly in tasks like SOP ranking. The integration of multimodal models in enterprise workflows presents opportunities for improving efficiency, accuracy, and scalability in diverse operational contexts.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"Comparison of Multimodal Foundation Models and Enterprise Workflows with metagpt\"}\n",
      "=== Function Output ===\n",
      "Multimodal Foundation Models and Enterprise Workflows are compared with MetaGPT based on their respective capabilities and applications in enhancing problem-solving capabilities and code generation quality. MetaGPT leverages SOPs to improve multi-agent systems using Large Language Models (LLMs) by modeling a group of agents as a simulated software company. It incorporates role specialization, workflow management, and efficient sharing mechanisms to create a flexible platform for autonomous agents. Additionally, MetaGPT utilizes an executable feedback mechanism to enhance code generation quality during runtime, leading to state-of-the-art performance on various benchmarks. This approach inspires future research on human-inspired techniques for artificial multi-agent systems and serves as an early attempt to regulate LLM-based multi-agent frameworks.\n",
      "=== LLM Response ===\n",
      "The paper discussing Multimodal Foundation Models and Enterprise Workflows focuses on the utilization of multimodal models in enterprise workflows to enhance automation, decision-making processes, and overall efficiency within organizations. These models combine natural language understanding with visual processing capabilities to address various business process management tasks, such as generating Standard Operating Procedures (SOPs), segmenting demonstrations, answering questions, validating workflows, and improving SOP quality. While these models have shown potential in improving SOP quality and adapting to changing workflows, challenges exist in aligning model judgments with human judgments, particularly in tasks like SOP ranking. The integration of multimodal models in enterprise workflows offers opportunities to enhance efficiency, accuracy, and scalability in diverse operational contexts.\n",
      "\n",
      "On the other hand, the metagpt paper compares Multimodal Foundation Models and Enterprise Workflows with MetaGPT based on their capabilities and applications in enhancing problem-solving abilities and code generation quality. MetaGPT utilizes SOPs to enhance multi-agent systems using Large Language Models (LLMs) by simulating a software company with a group of agents. It incorporates role specialization, workflow management, and efficient sharing mechanisms to create a flexible platform for autonomous agents. Additionally, MetaGPT employs an executable feedback mechanism to improve code generation quality during runtime, achieving state-of-the-art performance on various benchmarks. This approach inspires future research on human-inspired techniques for artificial multi-agent systems and serves as an initial effort to regulate LLM-based multi-agent frameworks.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Compare and contrast (1) the paper discussing Multimodal Foundation Models and Enterprise Workflows and (2) the metagpt paper.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper discussing Multimodal Foundation Models and Enterprise Workflows\n",
      "focuses on the utilization of multimodal models in enterprise workflows to\n",
      "enhance automation, decision-making processes, and overall efficiency within\n",
      "organizations. These models combine natural language understanding with visual\n",
      "processing capabilities to address various business process management tasks,\n",
      "such as generating Standard Operating Procedures (SOPs), segmenting\n",
      "demonstrations, answering questions, validating workflows, and improving SOP\n",
      "quality. While these models have shown potential in improving SOP quality and\n",
      "adapting to changing workflows, challenges exist in aligning model judgments\n",
      "with human judgments, particularly in tasks like SOP ranking. The integration\n",
      "of multimodal models in enterprise workflows offers opportunities to enhance\n",
      "efficiency, accuracy, and scalability in diverse operational contexts.  On the\n",
      "other hand, the metagpt paper compares Multimodal Foundation Models and\n",
      "Enterprise Workflows with MetaGPT based on their capabilities and applications\n",
      "in enhancing problem-solving abilities and code generation quality. MetaGPT\n",
      "utilizes SOPs to enhance multi-agent systems using Large Language Models (LLMs)\n",
      "by simulating a software company with a group of agents. It incorporates role\n",
      "specialization, workflow management, and efficient sharing mechanisms to create\n",
      "a flexible platform for autonomous agents. Additionally, MetaGPT employs an\n",
      "executable feedback mechanism to improve code generation quality during\n",
      "runtime, achieving state-of-the-art performance on various benchmarks. This\n",
      "approach inspires future research on human-inspired techniques for artificial\n",
      "multi-agent systems and serves as an initial effort to regulate LLM-based\n",
      "multi-agent frameworks.\n"
     ]
    }
   ],
   "source": [
    "print(display_text(response.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: According to the Ajua report, what were the main factors influencing custoner experience in dining?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_Ajua_Q2_2023_benchmark_report with args: {\"query\": \"factors influencing customer experience dining\"}\n",
      "=== Function Output ===\n",
      "Customer service, food and drink quality, and the ambiance of the outlet are the primary factors influencing customer experience dining.\n",
      "=== LLM Response ===\n",
      "According to the Ajua report, the main factors influencing customer experience in dining include customer service, food and drink quality, and the ambiance of the outlet.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"According to the Ajua report, what were the main factors influencing custoner experience in dining?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the Ajua report, the main factors influencing customer experience\n",
      "in dining include customer service, food and drink quality, and the ambiance of\n",
      "the outlet.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Good answer:  According to the Ajua report, the main factors influencing customer experience in dining include \n",
    "# customer service, food and drink quality, and the ambiance ofthe outlet.\n",
    "print(display_text(response.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">To do. Looking for a way to clear chat/memory. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not certain that this working\n",
    "agent.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Acording to the Ajua report, how did the NPS benchmark for Insurance change from Q2'22 to Q2'23?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_Ajua_Q2_2023_benchmark_report with args: {\"query\": \"NPS benchmark for Insurance\", \"page_numbers\": [1]}\n",
      "=== Function Output ===\n",
      "Empty Response\n",
      "=== LLM Response ===\n",
      "I couldn't find specific information on how the NPS benchmark for Insurance changed from Q2'22 to Q2'23 in the Ajua report. Would you like me to provide a summary of the report to see if there are any related insights?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"I couldn't find specific information on how the NPS benchmark for Insurance changed from Q2'22 to Q2'23 in the Ajua report. Would you like me to provide a summary of the report to see if there are any related insights?\", sources=[ToolOutput(content='Empty Response', tool_name='vector_tool_Ajua_Q2_2023_benchmark_report', raw_input={'args': (), 'kwargs': {'query': 'NPS benchmark for Insurance', 'page_numbers': [1]}}, raw_output=Response(response='Empty Response', source_nodes=[], metadata=None), is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"Acording to the Ajua report, how did the NPS benchmark for Insurance change from Q2'22 to Q2'23?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Remind me, what are we discussing?\n",
      "=== LLM Response ===\n",
      "We were discussing how the NPS benchmark for Insurance changed from Q2'22 to Q2'23 according to the Ajua report. Would you like me to provide a summary of the report to see if there are any related insights?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Remind me, what are we discussing?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not certain that this working\n",
    "agent.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Remind me, what are we discussing?\n",
      "=== LLM Response ===\n",
      "We are discussing enterprise workflows and their foundation models. How can I assist you further with this topic?\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Remind me, what are we discussing?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
