{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agentic RAG with Llamaindex\n",
    "source: https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/1/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, SummaryIndex, VectorStoreIndex\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters, FilterCondition\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "from utils import display_text\n",
    "from utils import filenames_in_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:30px;\">Setup</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary for running in Jupyter Notebook \n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">LlamaIndex RAG functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_path: str):\n",
    "    \"\"\"Load documents from the specified file path.\"\"\"\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    return documents\n",
    "\n",
    "def create_nodes(documents):\n",
    "    \"\"\"Create nodes from loaded documents.\"\"\"\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    return nodes\n",
    "\n",
    "def create_vector_index(nodes):\n",
    "    \"\"\"Create a vector index from nodes.\"\"\"\n",
    "    vector_index = VectorStoreIndex(nodes)\n",
    "    return vector_index\n",
    "\n",
    "def vector_query(\n",
    "    query: str, \n",
    "    vector_index: VectorStoreIndex, \n",
    "    page_numbers: Optional[List[str]] = None\n",
    ") -> str:\n",
    "    \"\"\"Use to answer questions over a given paper.\n",
    "\n",
    "    Useful if you have specific questions over the paper.\n",
    "    Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "    Args:\n",
    "        query (str): the string query to be embedded.\n",
    "        page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE \n",
    "            if we want to perform a vector search\n",
    "            over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    page_numbers = page_numbers or []\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(metadata_dicts, condition=FilterCondition.OR)\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def create_vector_query_tool(name: str, vector_index: VectorStoreIndex):\n",
    "    \"\"\"Create a vector query tool.\"\"\"\n",
    "    return FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\",\n",
    "        fn=lambda query, page_numbers=None: vector_query(query, vector_index, page_numbers)\n",
    "    )\n",
    "\n",
    "def create_summary_index(nodes):\n",
    "    \"\"\"Create a summary index from nodes.\"\"\"\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    return summary_index\n",
    "\n",
    "def create_summary_tool(name: str, summary_index: SummaryIndex):\n",
    "    \"\"\"Create a summary tool.\"\"\"\n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode=\"tree_summarize\",\n",
    "        use_async=True,\n",
    "    )\n",
    "    return QueryEngineTool.from_defaults(\n",
    "        name=f\"summary_tool_{name}\",\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(\n",
    "            \"Use ONLY IF you want to get a holistic summary related to {name} \"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">Load Data into RAG</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./input_docs\"\n",
    "papers = filenames_in_directory(file_path)\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_papers(papers, file_path):\n",
    "    \"\"\"\n",
    "    Process a list of papers and create tools for each paper.\n",
    "\n",
    "    Args:\n",
    "        papers (list): A list of paper filenames.\n",
    "        file_path (str): The path to the directory containing the papers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each paper to its associated tools.\n",
    "    \"\"\"\n",
    "    paper_to_tools_dict = {}\n",
    "    \n",
    "    for paper in papers:\n",
    "        name = f\"{Path(paper).stem}\"\n",
    "        print(f\"Getting tools for paper: {paper}\")\n",
    "        \n",
    "        # Assuming the following functions are defined elsewhere\n",
    "        documents = load_documents(f\"{file_path}/{Path(paper)}\")\n",
    "        nodes = create_nodes(documents)\n",
    "        vector_index = create_vector_index(nodes)\n",
    "        vector_query_tool = create_vector_query_tool(name, vector_index)\n",
    "        summary_index = create_summary_index(nodes)\n",
    "        summary_tool = create_summary_tool(name, summary_index)\n",
    "        \n",
    "        paper_to_tools_dict[paper] = [vector_query_tool, summary_tool]\n",
    "    \n",
    "    return paper_to_tools_dict\n",
    "\n",
    "paper_to_tools_dict = process_papers(papers, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of tools from all papers into a single list `all_tools`\n",
    "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]\n",
    "print(f\"number of tools: {len(all_tools)}\") #check (should be 2 * number of papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an \"object\" index and retriever over these tools\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n",
    "\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FunctionCallingAgentWorker\n",
    "# Verbose shows output of the agent's actions.\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retriever,\n",
    "    llm=llm, \n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given papers.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:30px\">Try it</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"Question goes here\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display_text(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.source_nodes[1].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not certain that this working\n",
    "agent.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:20px\">example</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
